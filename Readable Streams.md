#Streams
## ðŸ§± 1. What Are Streams?

Streams in Node.js allow data to be **read or written piece by piece (in chunks)** instead of loading the entire file into memory.

This is especially useful for **large files** (like videos, logs, backups, etc.) that canâ€™t fit into memory all at once.
## âš ï¸ 2. Why Not Just Use Buffers?

### âŒ Problems with Buffers:

- Buffers load the **entire file** into memory.
- Files **larger than 2 GiB** cannot be loaded.
- High memory usage â†’ slower performance.
- Increases CPU and RAM load.

## âœ… 3. Why Use Streams?

- Read files **chunk by chunk**.
- **Reduce memory usage**.
- Allow **real-time processing**.
- Enable **copying, uploading, or compressing large files** efficiently.
  
## ðŸ§© 4. Creating a Readable Stream

```js

import fs from "fs";
const stream = fs.createReadStream("./video.mp4", {
Â  highWaterMark: 1 * 1024 * 1024, // 1 MB per chunk
});

```
  
### ðŸ“˜ Parameters:

- `path`: Path of the file to read.
- `highWaterMark`: Size of each chunk in bytes. Â 
Â  Default = **64 KB** for files.

## ðŸŽ§ 5. Important Events on Readable Streams

| Event     | Description                                |
| --------- | ------------------------------------------ |
| `"data"`  | Fired every time a new chunk is available  |
| `"end"`   | Fired when there is no more data to read   |
| `"error"` | Fired if an error occurs                   |
| `"close"` | Fired when the stream is closed (optional) |

## âš™ï¸ 6. Reading File with Progress Percentage

```js

import { createReadStream } from "fs";
import fs from "fs/promises";

let fileSize = (await fs.stat("./video.mp4")).size;
let totalReceived = 0;

const stream = createReadStream("./video.mp4", { highWaterMark: 1 * 1024 * 1024 });

stream.on("data", async (chunk) => {
Â  totalReceived += chunk.byteLength;
Â  const percent = Math.floor((totalReceived / fileSize) * 100);
Â  process.stdout.write(`\rProgress: ${percent}%`);
Â  // optional delay
Â  await new Promise((r) => setTimeout(r, 100));
});

stream.on("end", () => {
Â  console.log("\nâœ… File read successfully!");
});

```

### ðŸ§  Tip:

Use `process.stdout.write("\r...")` instead of `console.log()` to show the percentage **in a single line** instead of multiple lines.

  
## ðŸ§¾ 7. Example: Copying a File with Stream and Showing Progress


```js

import fs from "fs";

const src = "./bigFile.mp4";
const dest = "./copy.mp4";

const { size } = fs.statSync(src);
const stream = fs.createReadStream(src, { highWaterMark: 10 * 1024 * 1024 });

  
let totalRead = 0;

stream.on("data", (chunk) => {
Â  fs.appendFileSync(dest, chunk);
Â  totalRead += chunk.length;
Â  const progress = ((totalRead / size) * 100).toFixed(2);
Â  process.stdout.write(`\rCopying... ${progress}%`);
});


stream.on("end", () => {
Â  console.log("\nâœ… File copied successfully!");
});

```


## ðŸ“Š 8. Understanding `highWaterMark`

- `highWaterMark` defines **chunk size** per read.
- **Smaller value â†’ less memory**, more time (more chunks).
- **Larger value â†’ faster**, but more memory used.

Example:

```js

const readStream = fs.createReadStream("file.mp4", { highWaterMark: 100 * 1024 }); // 100 KB
console.log(readStream.readableHighWaterMark); // shows actual chunk size

```

## ðŸ§  9. Common Mistakes to Avoid

| Mistake                                    | Why itâ€™s Wrong                           | Correct Way                         |
| ------------------------------------------ | ---------------------------------------- | ----------------------------------- |
| Using only `Buffer` for large files        | Causes memory overflow                   | Use `fs.createReadStream()`         |
| Printing progress using `console.log()`    | Creates multiple lines                   | Use `process.stdout.write("\r...")` |
| Forgetting to handle `'error'` event       | May crash program                        | Always add error handling           |
| Using Promises version of `fs` for streams | It doesnâ€™t support `.createReadStream()` | Use normal `fs` module              |
  
## ðŸ§° 10. Small Enhancements from Community Tips

âœ… **Show progress in same line**

```js
process.stdout.write(`\rProgress: ${percent}%`);
```

âœ… **Pause and resume stream (for rate control)**

```js
readStream.pause();
setTimeout(() => readStream.resume(), 100);
```

  
âœ… **Get total file size**

```js
const { size } = fs.statSync("file.mp4");
```

  
âœ… **Use async delay between chunks (for demo/testing)**

```js
await new Promise((r) => setTimeout(r, 100));
```

## ðŸ§© 11. Summary

| Concept                | Meaning                          |
| ---------------------- | -------------------------------- |
| Stream                 | Sequential chunk-based data flow |
| highWaterMark          | Defines buffer (chunk) size      |
| fs.createReadStream()  | Creates readable stream          |
| "data" event           | Fires when new chunk arrives     |
| "end" event            | Fires when file is done reading  |
| process.stdout.write() | Prints progress on same line     |
  
## ðŸ 12. Real-Life Use Cases

- Copying large video/audio files Â 
- Upload progress bar simulation Â 
- Reading logs gradually Â 
- Stream-based file servers Â 
- Video streaming applications Â 
## ðŸ˜’ My Style Progression 
 
 ```JS
// import fs from "fs/promises";

import fs from "fs";

let path = "E:\\Bike pay\\VID_20240405_175608.mp4";

const readStream = fs.createReadStream(path, {
Â  highWaterMark: 1 * 1024 * 1024,
});

let stat = fs.statSync(path);

readStream.on("data", (a) => {
Â  fs.appendFileSync("text.mp4", a);
Â  console.log(((readStream.bytesRead / stat.size) * 100).toFixed('1'));
});

 ```
## [[Different States of Readable Streams]]