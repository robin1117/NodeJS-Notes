#Streams
As in previous example we has seen that writable Streams too made high spike in RAM, and even why this problem occurring ?
This happens because mostly storage drives have different speeds of reading and writing data in it.
- Reading is Fast
- Writing is slow
So that means whatever the data `Reads stream` reads `Write stream` not able to write it as much of speed,
So it thrown the extra data in RAM as Backlog which make load over the ram
To fix this we have to apply backpressure `(stop reading when not needed)`

## âš ï¸ RAM Usage & Backpressure

Writing large or continuous data streams can quickly fill up memory. Â 
If the destination (like a file or socket) cannot keep up with incoming data, **backpressure** occurs.

Backpressure ensures your program **slows down writing** until the destination is ready to receive more data.


ğŸ§© To handle it properly, you can use the `'drain'` event:
  

```js

const canWrite = writeStream.write(bigData);

if (!canWrite) {
Â  writeStream.once("drain", () => {
Â  Â  console.log("Resuming writes after drain...");
Â  });

}

```

Writable streams in Node.js use an **internal buffer** to manage how data is written. Â 
If data is written faster than it can be flushed, we face **Backpressure** â€” a signal to slow down writing.

---
## ğŸ“¦ Internal Buffer

- Every writable stream maintains a buffer.
- `writeStream.writableLength` â†’ shows how much data (in bytes) is currently queued in the internal buffer.
- It can exceed `highWaterMark` if writes are very frequent.

---
## âš™ï¸ How `.write()` Works
  
```js
const ok = writeStream.write("some data");
```

- `.write()` returns:
Â  - âœ… `true` â†’ if `writableLength <= highWaterMark`
Â  - âŒ `false` â†’ if the internal buffer is full

ğŸ“Œ When it returns **false**, you must pause writing until the buffer drains.

---
## ğŸ”„ `drain` Event

```js
writeStream.on("drain", handler);
```

- Fires when the buffer is cleared, and the stream is ready for more data.
- Used to resume writing after `.write()` returned `false`.

---
## ğŸ§  Why Does Backpressure Happen?

  Backpressure happens when the writable stream **cannot keep up** with the incoming write speed, due to:

- Slower disk I/O Â 
- Network latency Â 
- File system bottlenecks Â 

ğŸ›‘ Writable streams **pause incoming writes** to avoid memory overload.

---

## My Example : 

```js
import fs from "fs";

const readStream = fs.createReadStream(
Â  "G:\\Godzilla.vs.Kong.mp4",
Â  { highWaterMark: 5 * 1024 * 1024 }
);

const writeStream = fs.createWriteStream("filrCreate.mp4", {
Â  highWaterMark: 5 * 1024 * 1024,
});

readStream.on("data", (chnk) => {
Â  let isEmpty = writeStream.write(chnk);
Â  console.log(isEmpty);
Â  if (!isEmpty) {
Â  Â  readStream.pause();
Â  }
});


writeStream.on("drain", () => {
Â  readStream.resume();
});

  
readStream.on("end", () => {
Â  writeStream.end(); // âœ… important â€” flushes and closes file
Â  readStream.close;
});
```


```js
function writeMany(writer, data, count) { Â 
Â  let i = 0; Â 
Â  function write() { Â  Â 
Â  Â  while (i < count) { Â  Â  Â 
Â  Â  Â  const ok = writer.write(data); Â  Â  Â 
Â  Â  Â  i++; Â  Â  Â 
Â  Â  Â  if (!ok) { Â  Â  Â  Â 
Â  Â  Â  Â  writer.once('drain', write); // Wait for buffer to drain Â  Â  Â  Â 
Â  Â  Â  Â  return; Â  Â  Â 
Â  Â  Â  } Â  Â 
Â  Â  } Â  Â 
Â  Â  writer.end(); Â 
Â  } Â 
Â  write();
}

writeMany(fs.createWriteStream("file.txt"), "Hello\n", 100000);
```

âœ… Efficient writing Â 
âœ… No memory overload Â 
âœ… Handles backpressure with `.once("drain")`


## [[Closing Writable Streams]] 

